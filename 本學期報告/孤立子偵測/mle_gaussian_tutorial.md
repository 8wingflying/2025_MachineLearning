# ğŸ“˜ é«˜æ–¯åˆ†å¸ƒçš„æœ€å¤§æ¦‚ä¼¼ä¼°è¨ˆï¼ˆMLE for Gaussian Distributionï¼‰

## ğŸ§© ä¸€ã€å‰è¨€

åœ¨çµ±è¨ˆå­¸èˆ‡æ©Ÿå™¨å­¸ç¿’ä¸­ï¼Œæˆ‘å€‘å¸¸ä½¿ç”¨æœ€å¤§æ¦‚ä¼¼ä¼°è¨ˆï¼ˆMaximum Likelihood Estimation, MLEï¼‰ä¾†ä¼°è¨ˆæ©Ÿç‡åˆ†å¸ƒçš„åƒæ•¸ã€‚  
å°æ–¼é«˜æ–¯åˆ†å¸ƒï¼ˆå¸¸æ…‹åˆ†å¸ƒï¼‰ï¼ŒMLE æä¾›äº†ä¸€ç¨®æ•¸å­¸ä¸Šæœ€è‡ªç„¶çš„æ–¹å¼ä¼°è¨ˆå…¶å¹³å‡æ•¸ï¼ˆÎ¼ï¼‰èˆ‡è®Šç•°æ•¸ï¼ˆÏƒÂ²ï¼‰ã€‚

---

## ğŸ“Š äºŒã€å¸¸æ…‹åˆ†å¸ƒå®šç¾©

å¸¸æ…‹åˆ†å¸ƒçš„æ©Ÿç‡å¯†åº¦å‡½æ•¸ï¼ˆPDFï¼‰ç‚ºï¼š

$$
f(x|\mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left[-\frac{(x - \mu)^2}{2\sigma^2}\right]
$$

åƒæ•¸ï¼š
- Î¼ï¼šæœŸæœ›å€¼ï¼ˆmeanï¼‰
- ÏƒÂ²ï¼šè®Šç•°æ•¸ï¼ˆvarianceï¼‰

---

## ğŸ¥® ä¸‰ã€ä¼¼ç„¶å‡½æ•¸ (Likelihood Function)

å‡è¨­æœ‰æ¨£æœ¬é›†  

$$
X = \{x_1, x_2, ..., x_n\}
$$

æ¯å€‹æ¨£æœ¬ç¨ç«‹ä¸”æœå¾ç›¸åŒçš„é«˜æ–¯åˆ†å¸ƒï¼š

$$
L(\mu, \sigma^2) = \prod_{i=1}^n f(x_i|\mu, \sigma^2)
$$

é€šå¸¸å–å°æ•¸ä»¥ä¾¿è¨ˆç®—ï¼š

$$
\ln L(\mu, \sigma^2) = -\frac{n}{2}\ln(2\pi) - \frac{n}{2}\ln(\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n (x_i - \mu)^2
$$

---

## ğŸ”¢ å››ã€å°åƒæ•¸æ±‚åå¾®åˆ†

### (1) å° Î¼ æ±‚åå¾®åˆ†ï¼š

$$
\frac{\partial \ln L}{\partial \mu} = \frac{1}{\sigma^2} \sum_{i=1}^n (x_i - \mu)
$$

ä»¤å…¶ç‚º 0ï¼š

$$
\sum_{i=1}^n (x_i - \mu) = 0 \Rightarrow \hat{\mu}_{MLE} = \frac{1}{n}\sum_{i=1}^n x_i
$$

âœ… **çµæœï¼šMLE å° Î¼ çš„ä¼°è¨ˆå€¼å°±æ˜¯æ¨£æœ¬å¹³å‡æ•¸ã€‚**

---

### (2) å° ÏƒÂ² æ±‚åå¾®åˆ†ï¼š

$$
\frac{\partial \ln L}{\partial \sigma^2} = -\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4}\sum_{i=1}^n (x_i - \mu)^2
$$

ä»¤å…¶ç‚º 0ï¼š

$$
-\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4}\sum_{i=1}^n (x_i - \mu)^2 = 0
$$

$$
\Rightarrow \hat{\sigma}^2_{MLE} = \frac{1}{n} \sum_{i=1}^n (x_i - \hat{\mu})^2
$$

âœ… **çµæœï¼šMLE å° ÏƒÂ² çš„ä¼°è¨ˆå€¼æ˜¯æ¨£æœ¬æ–¹å·®ï¼ˆä½†æ¯é«”åˆ†æ¯ç‚º nï¼Œè€Œé nâˆ’1ï¼‰ã€‚**

---

## ğŸ§  äº”ã€èˆ‡æ¨£æœ¬æ–¹å·®çš„é—œä¿‚

| ä¼°è¨ˆæ–¹æ³• | è®Šç•°æ•¸å…¬å¼ | åˆ†æ¯ | ç‰¹æ€§ |
|-----------|-------------|------|------|
| MLE | $\frac{1}{n}\sum(x_i - \bar{x})^2$ | n | ç„¡åä½†ä½ä¼°æ¯é«”è®Šç•° |
| ç„¡åä¼°è¨ˆ | $\frac{1}{n-1}\sum(x_i - \bar{x})^2$ | nâˆ’1 | å¸¸ç”¨æ–¼çµ±è¨ˆæ¨è«– |

---

## ğŸ’» å…­ã€Python å¯¦ä½œ

```python
import numpy as np

# å‡è¨­æˆ‘å€‘æœ‰æ¨£æœ¬è³‡æ–™
data = np.array([4.0, 5.2, 6.1, 5.8, 4.9])

# MLE ä¼°è¨ˆ Î¼ èˆ‡ ÏƒÂ²
mu_mle = np.mean(data)
sigma2_mle = np.mean((data - mu_mle)**2)

print(f"MLE Î¼ = {mu_mle:.4f}")
print(f"MLE ÏƒÂ² = {sigma2_mle:.4f}")
```

---

## ğŸ“ˆ ä¸ƒã€åœ–ç¤ºèªªæ˜ï¼ˆç›´è¦ºç†è§£ï¼‰

![Gaussian Curve Illustration](./images/gaussian_mle_diagram.png)

- **Î¼ (å¹³å‡å€¼)** æ±ºå®šäº†æ›²ç·šçš„ä¸­å¿ƒä½ç½®ã€‚
- **Ïƒ (æ¨™æº–å·®)** æ±ºå®šäº†æ›²ç·šçš„å¯¬åº¦ï¼ˆè¶Šå¤§è¶Šå¹³ç·©ï¼‰ã€‚
- MLE å˜—è©¦æ‰¾åˆ°ä¸€çµ„åƒæ•¸ï¼Œä½¿å¾—ã€Œè§€å¯Ÿåˆ°çš„è³‡æ–™å‡ºç¾çš„æ©Ÿç‡æœ€å¤§ã€‚ã€

---

## ğŸ§© å…«ã€ç¸½çµ

| é …ç›® | MLE çµæœ | è§£é‡‹ |
|------|------------|------|
| å¹³å‡å€¼ Î¼ | $\hat{\mu} = \frac{1}{n}\sum x_i $| æ¨£æœ¬å¹³å‡æ•¸ |
| è®Šç•°æ•¸ ÏƒÂ² | $\hat{\sigma}^2 = \frac{1}{n}\sum (x_i - \hat{\mu})^2$| æ¨£æœ¬æ–¹å·® (nåˆ†æ¯) |
| æ³¨æ„ | ç„¡åä¼°è¨ˆéœ€ç”¨ nâˆ’1 | çµ±è¨ˆå­¸å¸¸è¦‹ä¿®æ­£ |

---

ğŸ“˜ **å»¶ä¼¸é–±è®€**
- Bishop, *Pattern Recognition and Machine Learning* (2006)
- Murphy, *Machine Learning: A Probabilistic Perspective* (2012)
- Numpy å®˜æ–¹æ–‡ä»¶ï¼š[https://numpy.org/doc/](https://numpy.org/doc/)

