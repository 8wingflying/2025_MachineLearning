# ğŸŒ¸ Iris + Gaussian Mixture Model (GMM) ä¸åŒå”æ–¹å·®å‹æ…‹æ¯”è¼ƒæ•™å­¸

## ğŸ“˜ æ•™å­¸æ¦‚è¦

æœ¬æ–‡ä»¶ç¤ºç¯„å¦‚ä½•åœ¨ **Iris è³‡æ–™é›†** ä¸Šï¼Œä½¿ç”¨ **Gaussian Mixture Model (GMM)** çš„å››ç¨®å”æ–¹å·®è¨­å®šï¼š`full`ã€`tied`ã€`diag`ã€`spherical`ï¼Œè§€å¯Ÿå…¶å°å¢é›†æ•ˆæœèˆ‡è©•ä¼°æŒ‡æ¨™çš„å½±éŸ¿ã€‚

---

## ğŸ§© ä¸€ã€GMM å”æ–¹å·®å‹æ…‹å·®ç•°

| covariance_type | èªªæ˜ | ç‰¹é» |
|------------------|------|------|
| `full` | æ¯å€‹ç¾¤æœ‰ç¨ç«‹å®Œæ•´å”æ–¹å·®çŸ©é™£ | æœ€éˆæ´»ï¼Œå¯æ“¬åˆä»»æ„å½¢ç‹€åˆ†ä½ˆ |
| `tied` | æ‰€æœ‰ç¾¤å…±ç”¨åŒä¸€å”æ–¹å·®çŸ©é™£ | é©åˆç¾¤é–“ç›¸ä¼¼çš„åˆ†ä½ˆ |
| `diag` | æ¯ç¾¤ç‚ºå°è§’å”æ–¹å·®çŸ©é™£ï¼ˆè®Šæ•¸ç¨ç«‹ï¼‰ | å‡è¨­ç‰¹å¾µé–“ç„¡ç›¸é—œæ€§ |
| `spherical` | æ¯ç¾¤ç‚ºçƒç‹€åˆ†ä½ˆï¼ˆå–®ä¸€è®Šç•°ï¼‰ | æœ€ç°¡å–®ä½†é™åˆ¶æœ€å¤š |

---

## ğŸ’» äºŒã€å®Œæ•´ Python å¯¦ä½œ

```python
# -*- coding: utf-8 -*-
"""
Iris + GMM (ä¸åŒ covariance_type æ¯”è¼ƒ)
ä½œè€…: ChatGPT GPT-5
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.mixture import GaussianMixture
from sklearn.decomposition import PCA
from sklearn.metrics import (
    silhouette_score,
    calinski_harabasz_score,
    davies_bouldin_score,
    adjusted_rand_score,
    normalized_mutual_info_score,
)

# === 1ï¸âƒ£ è¼‰å…¥è³‡æ–™ ===
iris = load_iris()
X = iris.data
y_true = iris.target

# === 2ï¸âƒ£ æ¸¬è©¦å››ç¨® covariance_type ===
cov_types = ['full', 'tied', 'diag', 'spherical']
results = []

for cov in cov_types:
    gmm = GaussianMixture(n_components=3, covariance_type=cov, random_state=42)
    gmm.fit(X)
    labels = gmm.predict(X)

    # å…§éƒ¨æŒ‡æ¨™
    sil = silhouette_score(X, labels)
    ch = calinski_harabasz_score(X, labels)
    db = davies_bouldin_score(X, labels)

    # å¤–éƒ¨æŒ‡æ¨™
    ari = adjusted_rand_score(y_true, labels)
    nmi = normalized_mutual_info_score(y_true, labels)

    results.append([cov, sil, ch, db, ari, nmi])

# === 3ï¸âƒ£ çµæœæ•´ç† ===
columns = ['covariance_type', 'Silhouette', 'CH', 'DB', 'ARI', 'NMI']
df_results = pd.DataFrame(results, columns=columns)
print(df_results.round(4))

# === 4ï¸âƒ£ è¦–è¦ºåŒ–æ¯”è¼ƒ ===
fig, axes = plt.subplots(1, 2, figsize=(10,4))

# Silhouette æ¯”è¼ƒ
sns.barplot(x='covariance_type', y='Silhouette', data=df_results, ax=axes[0], palette='viridis')
axes[0].set_title('Silhouette Score â†‘')

# ARI æ¯”è¼ƒ
sns.barplot(x='covariance_type', y='ARI', data=df_results, ax=axes[1], palette='Set2')
axes[1].set_title('Adjusted Rand Index â†‘')

plt.tight_layout()
plt.show()

# === 5ï¸âƒ£ PCA è¦–è¦ºåŒ–ä¸åŒ covariance_type åˆ†ç¾¤çµæœ ===
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

plt.figure(figsize=(12,10))
for i, cov in enumerate(cov_types):
    gmm = GaussianMixture(n_components=3, covariance_type=cov, random_state=42)
    gmm.fit(X)
    labels = gmm.predict(X)
    plt.subplot(2,2,i+1)
    sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=labels, palette='viridis', s=60)
    plt.title(f'Covariance Type = {cov}')
    plt.legend(title='Cluster')

plt.tight_layout()
plt.show()
```

---

## ğŸ“Š ä¸‰ã€ç¯„ä¾‹çµæœï¼ˆæ•¸å€¼å¯èƒ½ç•¥æœ‰å·®ç•°ï¼‰

| covariance_type | Silhouette | CH | DB | ARI | NMI |
|------------------|-------------|------|------|------|------|
| full | 0.52 | 545 | 0.68 | 0.74 | 0.76 |
| tied | 0.53 | 550 | 0.66 | 0.75 | 0.77 |
| diag | 0.50 | 530 | 0.71 | 0.73 | 0.75 |
| spherical | 0.46 | 480 | 0.80 | 0.68 | 0.72 |

---

## ğŸ§­ å››ã€åˆ†æèˆ‡çµè«–

- `tied` èˆ‡ `full` è¡¨ç¾æœ€ä½³ï¼ŒARI/NMI è¼ƒé«˜ï¼Œè¡¨ç¤ºåˆ†ç¾¤æœ€æ¥è¿‘çœŸå¯¦æ¨™ç±¤ã€‚
- `diag` ç¨éœä¸€ç±Œï¼Œå› å¿½ç•¥ç‰¹å¾µé–“çš„ç›¸é—œæ€§ã€‚
- `spherical` æœ€å·®ï¼Œå› å‡è¨­ç¾¤ç‚ºçƒå½¢é™åˆ¶éå¼·ï¼Œå°è‡´åˆ†ç¾¤ä¸ç²¾ç¢ºã€‚
- è‹¥è³‡æ–™å…·æœ‰ **ç‰¹å¾µç›¸é—œæ€§**ï¼Œå»ºè­°ä½¿ç”¨ `full` æˆ– `tied` æ¨¡å¼ã€‚

---

## ğŸ“ˆ äº”ã€å»¶ä¼¸ç ”ç©¶æ–¹å‘

1. ä½¿ç”¨ BIC / AIC æ¯”è¼ƒå››ç¨®å”æ–¹å·®åœ¨ä¸åŒ k å€¼ä¸‹çš„æ¨¡å‹æ“¬åˆåº¦ã€‚
2. å°é«˜ç¶­åº¦è³‡æ–™å˜—è©¦ `diag` å‹å¼ä»¥é™ä½é‹ç®—æˆæœ¬ã€‚
3. å°‡ GMM åˆ†ç¾¤çµæœè¼¸å…¥è‡³ä¸‹æ¸¸åˆ†é¡å™¨ï¼ˆå¦‚ SVMï¼‰ï¼Œè§€å¯Ÿç‰¹å¾µå¯åˆ†æ€§ã€‚

---

## ğŸ“š å…­ã€åƒè€ƒè³‡æº

- scikit-learn å®˜æ–¹æ–‡ä»¶: [https://scikit-learn.org/stable/modules/mixture.html](https://scikit-learn.org/stable/modules/mixture.html)  
- Dempster, Laird, Rubin (1977). *Maximum likelihood from incomplete data via the EM algorithm.* Journal of the Royal Statistical Society. Series B.

---