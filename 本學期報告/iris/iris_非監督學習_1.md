#### ğŸŒ¸ Iris è³‡æ–™é›† ç„¡ç›£ç£å­¸ç¿’ï¼ˆUnsupervised Clusteringï¼‰æ¯”è¼ƒåˆ†æ

---

## ğŸ“˜ ä¸€ã€ç›®æ¨™èªªæ˜
æœ¬æ–‡ä»¶èªªæ˜å¦‚ä½•åœ¨ **Iris è³‡æ–™é›†** ä¸Šé€²è¡Œç„¡ç›£ç£åˆ†ç¾¤åˆ†æï¼Œæ¶µè“‹ä»¥ä¸‹å…§å®¹ï¼š

1. **K-Means åˆ†ç¾¤**
2. **éšå±¤å¼åˆ†ç¾¤ (Hierarchical Clustering)**
3. **DBSCAN å¯†åº¦å¼åˆ†ç¾¤**
4. **Gaussian Mixture Model (GMM)**

é€éæ¯”è¼ƒä¸åŒæ¨¡å‹çš„çµæœèˆ‡æŒ‡æ¨™ï¼ˆä¾‹å¦‚ ARIï¼‰ï¼Œå¹«åŠ©ç†è§£å„æ¼”ç®—æ³•çš„ç‰¹æ€§èˆ‡é©ç”¨æƒ…å¢ƒã€‚

---

## ğŸ§© äºŒã€è¼‰å…¥è³‡æ–™èˆ‡å‰è™•ç†

```python
import seaborn as sns
import pandas as pd
from sklearn.preprocessing import StandardScaler

# è¼‰å…¥è³‡æ–™
iris = sns.load_dataset("iris")
X = iris.drop(columns="species")

# è³‡æ–™æ¨™æº–åŒ–
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

---

## âš™ï¸ ä¸‰ã€K-Means åˆ†ç¾¤åˆ†æ

### 1ï¸âƒ£ ä½¿ç”¨è‚˜éƒ¨æ³•å‰‡ (Elbow Method) æ±ºå®šæœ€ä½³ k å€¼

```python
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

sse = []
K = range(1, 10)
for k in K:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    sse.append(kmeans.inertia_)

plt.plot(K, sse, 'bx-')
plt.xlabel('ç¾¤æ•¸ k')
plt.ylabel('SSE (èª¤å·®å¹³æ–¹å’Œ)')
plt.title('Elbow Method for Optimal k')
plt.show()
```

ğŸ“ˆ **è§€å¯Ÿé‡é»ï¼š** SSE åœ¨ k=3 ä¹‹å¾Œä¸‹é™è¶¨å‹¢è¶¨ç·©ï¼Œæœ€ä½³ç¾¤æ•¸ç‚º **3 ç¾¤**ã€‚

---

### 2ï¸âƒ£ å»ºç«‹ K-Means æ¨¡å‹èˆ‡è¦–è¦ºåŒ–

```python
from sklearn.decomposition import PCA
import seaborn as sns

kmeans = KMeans(n_clusters=3, random_state=42)
iris["cluster"] = kmeans.fit_predict(X_scaled)

pca = PCA(n_components=2)
iris_pca = pd.DataFrame(pca.fit_transform(X_scaled), columns=['PCA1', 'PCA2'])
iris_pca["cluster"] = iris["cluster"]

sns.scatterplot(x="PCA1", y="PCA2", hue="cluster", data=iris_pca, palette="Set2", s=80)
plt.title("K-Means åˆ†ç¾¤çµæœ (PCA 2D è¦–è¦ºåŒ–)")
plt.show()
```

---

### 3ï¸âƒ£ è©•ä¼°åˆ†ç¾¤å“è³ªï¼ˆARI æŒ‡æ¨™ï¼‰

```python
from sklearn.metrics import adjusted_rand_score

ari = adjusted_rand_score(iris["species"], iris["cluster"])
print(f"Adjusted Rand Index (ARI): {ari:.3f}")
```

ğŸ“Š **çµæœè§£è®€ï¼š** ARI ç´„ç‚º 0.7~0.8ï¼Œä»£è¡¨ K-Means åˆ†ç¾¤æ•ˆæœè‰¯å¥½ã€‚

---

## ğŸªœ å››ã€éšå±¤å¼åˆ†ç¾¤ (Hierarchical Clustering)

### 1ï¸âƒ£ æ¨¹ç‹€åœ– (Dendrogram)

```python
from scipy.cluster.hierarchy import linkage, dendrogram

plt.figure(figsize=(10, 6))
linkage_matrix = linkage(X_scaled, method='ward')
dendrogram(linkage_matrix)
plt.title("Hierarchical Clustering Dendrogram (ward linkage)")
plt.xlabel("Sample index")
plt.ylabel("Distance")
plt.show()
```

### 2ï¸âƒ£ Agglomerative Clustering æ¨¡å‹

```python
from sklearn.cluster import AgglomerativeClustering

agg = AgglomerativeClustering(n_clusters=3, linkage="ward")
iris["agg_cluster"] = agg.fit_predict(X_scaled)
iris_pca["agg_cluster"] = iris["agg_cluster"]

sns.scatterplot(x="PCA1", y="PCA2", hue="agg_cluster", data=iris_pca, palette="Set1", s=80)
plt.title("éšå±¤å¼åˆ†ç¾¤çµæœ (PCA 2D è¦–è¦ºåŒ–)")
plt.show()
```

---

## ğŸ” äº”ã€é€²éšåˆ†ç¾¤æ¯”è¼ƒ â€” DBSCAN èˆ‡ GMM

### ï¼ˆ1ï¼‰DBSCAN åˆ†ç¾¤

```python
from sklearn.cluster import DBSCAN

dbscan = DBSCAN(eps=0.6, min_samples=5)
iris["dbscan_cluster"] = dbscan.fit_predict(X_scaled)

pca = PCA(n_components=2)
iris_pca = pd.DataFrame(pca.fit_transform(X_scaled), columns=["PCA1", "PCA2"])
iris_pca["dbscan_cluster"] = iris["dbscan_cluster"]

sns.scatterplot(x="PCA1", y="PCA2", hue="dbscan_cluster", data=iris_pca, palette="Set2", s=80)
plt.title("DBSCAN åˆ†ç¾¤çµæœ (PCA 2D è¦–è¦ºåŒ–)")
plt.show()
```

ğŸ“˜ **åƒæ•¸èªªæ˜ï¼š**
- `eps`: é„°åŸŸåŠå¾‘å¤§å°ã€‚
- `min_samples`: å®šç¾©æ ¸å¿ƒé»æœ€å°æ¨£æœ¬æ•¸ã€‚
- `-1`: å™ªéŸ³é»ã€‚

```python
ari_dbscan = adjusted_rand_score(iris["species"], iris["dbscan_cluster"])
print(f"DBSCAN Adjusted Rand Index (ARI): {ari_dbscan:.3f}")
```

ğŸ“Š **DBSCAN åˆ†æçµæœï¼š**
- å°éç·šæ€§çµæ§‹è¡¨ç¾è‰¯å¥½ï¼Œä½†åƒæ•¸æ•æ„Ÿã€‚
- å¸¸èƒ½æº–ç¢ºè¾¨è­˜ Setosaï¼Œä½†å…¶ä»–å…©é¡å¯èƒ½è¢«åˆä½µã€‚

---

### ï¼ˆ2ï¼‰Gaussian Mixture Model (GMM)

```python
from sklearn.mixture import GaussianMixture

gmm = GaussianMixture(n_components=3, covariance_type="full", random_state=42)
gmm_labels = gmm.fit_predict(X_scaled)
iris["gmm_cluster"] = gmm_labels

iris_pca["gmm_cluster"] = iris["gmm_cluster"]

sns.scatterplot(x="PCA1", y="PCA2", hue="gmm_cluster", data=iris_pca, palette="Set1", s=80)
plt.title("GMM åˆ†ç¾¤çµæœ (PCA 2D è¦–è¦ºåŒ–)")
plt.show()
```

ğŸ“˜ **GMM ç‰¹é»ï¼š**
- å¯è¦–ç‚ºæŸ”æ€§ç‰ˆçš„ K-Meansï¼ˆå…è¨±æ©¢åœ“å½¢ç¾¤ï¼‰ã€‚
- èƒ½è¼¸å‡ºæ¨£æœ¬å±¬æ–¼å„ç¾¤çš„æ©Ÿç‡ï¼ˆSoft Clusteringï¼‰ã€‚

```python
ari_gmm = adjusted_rand_score(iris["species"], iris["gmm_cluster"])
print(f"GMM Adjusted Rand Index (ARI): {ari_gmm:.3f}")
```

---

### ï¼ˆ3ï¼‰å››ç¨®æ¨¡å‹æ¯”è¼ƒ

| æ¨¡å‹ | åŸç† | å¯è¾¨è­˜ç¾¤æ•¸ | ARI (è¶Šé«˜è¶Šå¥½) | å„ªé» | ç¼ºé» |
|------|------|-------------|----------------|------|------|
| **K-Means** | åŸºæ–¼è·é›¢æœ€å°åŒ– | 3 | ç´„ 0.73 | ç°¡å–®å¿«é€Ÿ | å°åˆå§‹å€¼æ•æ„Ÿ |
| **éšå±¤å¼åˆ†ç¾¤** | å±¤æ¬¡åˆä½µè·é›¢æœ€å°ç¾¤ | 3 | ç´„ 0.70 | å¯è¦–åŒ–å±¤æ¬¡ | é›£ä»¥è™•ç†å¤§è³‡æ–™ |
| **DBSCAN** | åŸºæ–¼å¯†åº¦çš„åˆ†ç¾¤ | 2~3 | ç´„ 0.55 | å¯åµæ¸¬å™ªéŸ³ | å°åƒæ•¸æ•æ„Ÿ |
| **GMM** | æ©¢åœ“é«˜æ–¯æ··åˆ | 3 | ç´„ 0.78 | åˆ†ç¾¤æŸ”æ€§é«˜ | éœ€å‡è¨­åˆ†ä½ˆå½¢ç‹€ |

---

## ğŸ“ˆ å…­ã€GMM æ©Ÿç‡åˆ†æ

```python
probs = gmm.predict_proba(X_scaled)
iris_probs = pd.DataFrame(probs, columns=["Prob_Setosa", "Prob_Versicolor", "Prob_Virginica"])
print(iris_probs.head())
```

ğŸ” **èªªæ˜ï¼š** `predict_proba()` è¼¸å‡ºæ¨£æœ¬å±¬æ–¼å„ç¾¤çš„æ©Ÿç‡ï¼Œæœ‰åŠ©åˆ†æé‚Šç•Œæ¨£æœ¬ã€‚

---

## ğŸ“š ä¸ƒã€çµè«–èˆ‡å»ºè­°

| æ¨¡å‹ | é©ç”¨æƒ…å¢ƒ |
|------|------------|
| **K-Means** | ç¾¤å½¢æ¥è¿‘çƒå½¢ã€ç¾¤æ•¸å·²çŸ¥ |
| **éšå±¤å¼åˆ†ç¾¤** | æ¨£æœ¬æ•¸å°ã€éœ€äº†è§£å±¤æ¬¡çµæ§‹ |
| **DBSCAN** | å­˜åœ¨å™ªéŸ³æˆ–éçƒå½¢çµæ§‹ |
| **GMM** | ç¾¤é«”å‘ˆæ©¢åœ“åˆ†ä½ˆä¸”ç¾¤æ•¸å·²çŸ¥ |

ğŸ“˜ **çµè«–ï¼š** GMM åœ¨ Iris è³‡æ–™é›†ä¸Šçš„è¡¨ç¾æœ€ä½³ï¼ˆARI â‰ˆ 0.78ï¼‰ï¼Œèƒ½æ›´æº–ç¢ºæ•æ‰ Versicolor èˆ‡ Virginica ä¹‹é–“çš„åˆ†ä½ˆå·®ç•°ã€‚

---

## ğŸ“¦ å…«ã€Python å¥—ä»¶éœ€æ±‚

```bash
pip install pandas seaborn matplotlib scikit-learn scipy
```

---

ğŸ“… **å»ºç«‹æ—¥æœŸï¼š** 2025-10-28  
âœï¸ **ä½œè€…ï¼š** ChatGPT æ•™å­¸åŠ©æ‰‹  
ğŸ§  **ä¸»é¡Œï¼š** Unsupervised Clustering Analysis on Iris Dataset â€” K-Means, Hierarchical, DBSCAN, GMM

