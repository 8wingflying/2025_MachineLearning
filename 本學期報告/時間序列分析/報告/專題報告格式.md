# å°ˆé¡Œå ±å‘Šæ ¼å¼
```
æ·±åº¦æ•´åˆç‰ˆ app.pyã€ï¼ŒåŒ…å«ï¼š
âœ… CSV ä¸Šå‚³
âœ… è‡ªå‹•åŒ– EDAï¼ˆæè¿°çµ±è¨ˆã€ç¼ºå¤±å€¼ã€ç†±åŠ›åœ–ã€åˆ†ä½ˆåœ–ï¼‰
âœ… AutoMLï¼ˆåˆ†é¡ / å›æ­¸ï¼Œè‡ªå‹•åˆ¤æ–·ä»»å‹™ï¼‰
âœ… ç•°å¸¸åµæ¸¬ï¼ˆIsolation Forest + LOF + 2D è¦–è¦ºåŒ– + äº¤é›†ï¼‰
âœ… æ™‚é–“åºåˆ—åˆ†æ Tab
æ™‚é–“æ¬„ä½è‡ªå‹•åµæ¸¬ / å¯æ‰‹å‹•é¸
æ•¸å€¼æ¬„ä½ y é¸æ“‡
æŠ˜ç·šåœ– + MA7 / MA30
ACF / PACF
Auto ARIMAï¼ˆpmdarimaï¼‰
æ‰‹å‹• ARIMAï¼ˆstatsmodelsï¼‰
é æ¸¬å¤©æ•¸ã€Œè‡ªç”±è¼¸å…¥ã€
âœ… è‡ªå‹•ç”¢ç”Ÿã€Œæ•™å­¸ç‰ˆã€é¢¨æ ¼çš„ Markdown å ±å‘Šï¼ˆå« TS æ‘˜è¦ï¼‰ï¼Œå¯ä¸‹è¼‰ .md
âœ… è‡ªå‹•åµæ¸¬ä¸¦å®‰è£ pmdarima / statsmodelsï¼ˆä½ é¸çš„é¸é … 2ï¼‰

ä½ åªè¦ï¼šå»ºä¸€å€‹ app.pyï¼Œè²¼ä¸Šä¸‹é¢ç¨‹å¼ç¢¼ï¼Œç„¶å¾ŒåŸ·è¡Œï¼š

streamlit run app.py
```
```python
import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import io
import sys
import subprocess

# =============================
# å˜—è©¦åŒ¯å…¥æ™‚é–“åºåˆ—ç›¸é—œå¥—ä»¶ï¼ˆè‹¥ç„¡å‰‡è‡ªå‹• pip installï¼‰
# =============================
def safe_import_ts_packages():
    ts_state = {
        "pmdarima": None,
        "statsmodels_acf": None,
        "statsmodels_pacf": None,
        "ARIMA": None
    }

    # å˜—è©¦åŒ¯å…¥ pmdarima
    try:
        import pmdarima as pm
        ts_state["pmdarima"] = pm
    except ImportError:
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "pmdarima", "statsmodels"])
            import pmdarima as pm
            ts_state["pmdarima"] = pm
        except Exception:
            ts_state["pmdarima"] = None

    # å˜—è©¦åŒ¯å…¥ statsmodels
    try:
        from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
        from statsmodels.tsa.arima.model import ARIMA
        ts_state["statsmodels_acf"] = plot_acf
        ts_state["statsmodels_pacf"] = plot_pacf
        ts_state["ARIMA"] = ARIMA
    except Exception:
        # è‹¥ä¸Šé¢æ²’æˆåŠŸï¼Œå˜—è©¦å®‰è£
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "statsmodels"])
            from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
            from statsmodels.tsa.arima.model import ARIMA
            ts_state["statsmodels_acf"] = plot_acf
            ts_state["statsmodels_pacf"] = plot_pacf
            ts_state["ARIMA"] = ARIMA
        except Exception:
            ts_state["statsmodels_acf"] = None
            ts_state["statsmodels_pacf"] = None
            ts_state["ARIMA"] = None

    return ts_state


ts_pkgs = safe_import_ts_packages()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, f1_score, classification_report,
    mean_squared_error, r2_score
)
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, IsolationForest
from sklearn.neighbors import LocalOutlierFactor


# =============================
# Streamlit åŸºæœ¬è¨­å®š + UI ä¸»é¡Œ
# =============================
st.set_page_config(page_title="ğŸ“Š è‡ªå‹•åŒ– EDA + AutoML + æ™‚é–“åºåˆ— å¹³å°", layout="wide")

# è¼‰å…¥ Bootstrap
st.markdown("""
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css"
/>
""", unsafe_allow_html=True)

# å´é‚Šæ¬„ä¸»é¡Œé¸æ“‡
theme = st.sidebar.selectbox("ğŸ¨ ä¸»é¡Œæ¨£å¼", ["é è¨­", "é›è—æ·±è‰²", "ç¶ è‰²äº®è‰²"])

if theme == "é›è—æ·±è‰²":
    st.markdown("""
    <style>
    .stApp { background-color: #020617; color: #e5e7eb; }
    .block-container { padding-top: 1rem; }
    </style>
    """, unsafe_allow_html=True)
elif theme == "ç¶ è‰²äº®è‰²":
    st.markdown("""
    <style>
    .stApp { background-color: #ecfdf5; }
    .block-container { padding-top: 1rem; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ“Š è‡ªå‹•åŒ– EDA + AutoML + ç•°å¸¸åµæ¸¬ + æ™‚é–“åºåˆ—åˆ†æ å¹³å°")

st.write("""
æ­¤å¹³å°æ•´åˆï¼š
- æè¿°çµ±è¨ˆèˆ‡ EDA
- AutoMLï¼ˆåˆ†é¡ / å›æ­¸ï¼‰
- ç•°å¸¸åµæ¸¬ï¼ˆIsolation Forest / LOFï¼‰
- æ™‚é–“åºåˆ—åˆ†æï¼ˆACF / PACF / ARIMAï¼‰
- è‡ªå‹•ç”¢ç”Ÿ Markdown æ•™å­¸å ±å‘Šï¼ˆå¯ä¸‹è¼‰ï¼‰
""")

# =============================
# Session Stateï¼šå ±å‘Šæ‘˜è¦å€
# =============================
if "ml_summary" not in st.session_state:
    st.session_state["ml_summary"] = "å°šæœªåŸ·è¡Œ ML å»ºæ¨¡ã€‚"

if "anom_summary" not in st.session_state:
    st.session_state["anom_summary"] = "å°šæœªåŸ·è¡Œç•°å¸¸åµæ¸¬ã€‚"

if "ts_summary" not in st.session_state:
    st.session_state["ts_summary"] = "å°šæœªåŸ·è¡Œæ™‚é–“åºåˆ—åˆ†æã€‚"

# =============================
# ä¸Šå‚³ CSV
# =============================
uploaded_file = st.sidebar.file_uploader("ğŸ“ ä¸Šå‚³ CSV æª”æ¡ˆ", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.success(f"âœ… æˆåŠŸè¼‰å…¥è³‡æ–™ï¼š{df.shape[0]} ç­† Ã— {df.shape[1]} æ¬„")

    # è‡ªå‹•åµæ¸¬æ¬„ä½å‹æ…‹
    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
    cat_cols = df.select_dtypes(include="object").columns.tolist()

    # =============================
    # è‡ªå‹•åµæ¸¬å¯èƒ½çš„æ™‚é–“æ¬„ä½
    # =============================
    candidate_time_cols = []
    # å…ˆæŠ“ dtype å·²ç¶“æ˜¯ datetime çš„æ¬„ä½
    candidate_time_cols.extend(df.select_dtypes(include=["datetime64[ns]", "datetime64[ns, UTC]"]).columns.tolist())

    # å†å¾ object ä¸­ç”¨æ¬„ä½åç¨±çŒœæ¸¬
    time_keywords = ["date", "time", "datetime", "timestamp", "æ—¥æœŸ", "æ™‚é–“"]
    for col in df.columns:
        low = col.lower()
        if any(k in low for k in time_keywords) and col not in candidate_time_cols:
            candidate_time_cols.append(col)

    # Tabsï¼šEDA / AutoML / ç•°å¸¸ / æ™‚åº / å ±å‘Š
    tab_eda, tab_ml, tab_anom, tab_ts, tab_report = st.tabs(
        ["ğŸ“ˆ EDA / æè¿°çµ±è¨ˆ", "ğŸ¤– AutoMLï¼ˆåˆ†é¡/å›æ­¸ï¼‰", "ğŸš¨ ç•°å¸¸åµæ¸¬", "â±ï¸ æ™‚é–“åºåˆ—åˆ†æ", "ğŸ“„ Markdown å ±å‘Š"]
    )

    # =============================
    # Tab 1ï¼šEDA / æè¿°çµ±è¨ˆ
    # =============================
    with tab_eda:
        st.header("ğŸ“ˆ Exploratory Data Analysisï¼ˆEDAï¼‰")

        st.subheader("ğŸ” å‰äº”ç­†è³‡æ–™")
        st.dataframe(df.head())

        st.subheader("ğŸ“Œ åŸºç¤è³‡è¨Š Info")
        buffer = io.StringIO()
        df.info(buf=buffer)
        info_str = buffer.getvalue()
        st.text(info_str)

        st.subheader("ğŸ§© ç¼ºå¤±å€¼åˆ†æ")
        missing_df = df.isnull().sum().to_frame("ç¼ºå¤±æ•¸é‡")
        missing_df["ç¼ºå¤±æ¯”ä¾‹ (%)"] = (missing_df["ç¼ºå¤±æ•¸é‡"] / len(df)) * 100
        st.dataframe(missing_df)

        st.subheader("ğŸ“Š æè¿°çµ±è¨ˆï¼ˆDescriptive Statisticsï¼‰")
        st.dataframe(df.describe(include="all"))

        # æ•¸å€¼æ¬„ä½è¦–è¦ºåŒ–
        if len(numeric_cols) > 0:
            st.subheader("ğŸ“‰ æ•¸å€¼æ¬„ä½åˆ†ä½ˆåœ–")
            col = st.selectbox("é¸æ“‡æ¬„ä½", numeric_cols, key="dist_col")
            fig, ax = plt.subplots()
            sns.histplot(df[col].dropna(), kde=True, ax=ax)
            ax.set_title(f"Distribution of {col}")
            st.pyplot(fig)

            st.subheader("ğŸ”¥ ç›¸é—œçŸ©é™£ç†±åŠ›åœ– (Correlation Heatmap)")
            corr = df[numeric_cols].corr()
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f")
            st.pyplot(fig)

        # é¡åˆ¥æ¬„ä½è¦–è¦ºåŒ–
        if len(cat_cols) > 0:
            st.subheader("ğŸ·ï¸ é¡åˆ¥æ¬„ä½åˆ†æ")
            col = st.selectbox("é¸æ“‡é¡åˆ¥æ¬„ä½", cat_cols, key="cat_col")
            st.write("é¡åˆ¥çµ±è¨ˆï¼š")
            st.dataframe(df[col].value_counts().to_frame("æ¬¡æ•¸"))

            fig, ax = plt.subplots()
            sns.countplot(x=df[col], ax=ax)
            plt.xticks(rotation=45)
            ax.set_title(f"Count Plot of {col}")
            st.pyplot(fig)

    # =============================
    # Tab 2ï¼šAutoMLï¼ˆåˆ†é¡ / å›æ­¸ï¼‰
    # =============================
    with tab_ml:
        st.header("ğŸ¤– è‡ªå‹• ML å»ºæ¨¡ï¼ˆåˆ†é¡ / å›æ­¸ï¼‰")

        target_col = st.selectbox("é¸æ“‡ç›®æ¨™æ¬„ä½ï¼ˆyï¼‰", df.columns)

        # è‡ªå‹•åˆ¤æ–·ä»»å‹™é¡å‹
        unique_vals = df[target_col].nunique()
        if df[target_col].dtype == "object" or unique_vals <= 10:
            auto_task = "åˆ†é¡"
        else:
            auto_task = "å›æ­¸"

        task = st.radio(
            "é¸æ“‡ä»»å‹™é¡å‹",
            ["è‡ªå‹•åµæ¸¬", "åˆ†é¡", "å›æ­¸"],
            index=0,
            horizontal=True
        )

        task_type = auto_task if task == "è‡ªå‹•åµæ¸¬" else task

        st.info(f"ğŸ” ç³»çµ±åˆ¤æ–·å»ºè­°ä»»å‹™ï¼š**{auto_task}**ï¼Œç›®å‰åŸ·è¡Œï¼š**{task_type}**")

        if st.button("ğŸš€ åŸ·è¡Œ AutoML å»ºæ¨¡"):
            data = df.dropna(subset=[target_col]).copy()
            y = data[target_col]

            # one-hot encoding
            X = pd.get_dummies(data.drop(columns=[target_col]), drop_first=True)

            if X.shape[1] == 0:
                st.error("æ²’æœ‰å¯ç”¨çš„ç‰¹å¾µæ¬„ä½ï¼ˆXï¼‰ã€‚è«‹ç¢ºèªè³‡æ–™å…§å®¹ã€‚")
            else:
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42
                )

                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)

                ml_report_lines = []

                # ===== åˆ†é¡ä»»å‹™ =====
                if task_type == "åˆ†é¡":
                    st.subheader("ğŸŒ² RandomForestClassifier æ¨¡å‹")
                    clf = RandomForestClassifier(
                        n_estimators=200, random_state=42
                    )
                    clf.fit(X_train, y_train)
                    y_pred = clf.predict(X_test)

                    acc = accuracy_score(y_test, y_pred)
                    f1 = f1_score(y_test, y_pred, average="weighted")

                    st.write(f"âœ… Accuracyï¼š**{acc:.4f}**")
                    st.write(f"âœ… F1-score (weighted)ï¼š**{f1:.4f}**")

                    st.text("Classification Reportï¼š")
                    cls_report = classification_report(y_test, y_pred)
                    st.text(cls_report)

                    importances = pd.Series(
                        clf.feature_importances_, index=X.columns
                    ).sort_values(ascending=False).head(15)
                    st.write("ğŸ“Œ å‰ 15 å€‹é‡è¦ç‰¹å¾µï¼š")
                    st.dataframe(importances.to_frame("importance"))

                    fig, ax = plt.subplots(figsize=(8, 4))
                    importances.sort_values().plot(kind="barh", ax=ax)
                    ax.set_title("Feature Importances (Top 15)")
                    st.pyplot(fig)

                    ml_report_lines.append("### åˆ†é¡æ¨¡å‹çµæœï¼ˆRandomForestClassifierï¼‰")
                    ml_report_lines.append(f"- Accuracyï¼š{acc:.4f}")
                    ml_report_lines.append(f"- F1-score (weighted)ï¼š{f1:.4f}")

                # ===== å›æ­¸ä»»å‹™ =====
                else:
                    st.subheader("ğŸŒ² RandomForestRegressor æ¨¡å‹")
                    reg = RandomForestRegressor(
                        n_estimators=200, random_state=42
                    )
                    reg.fit(X_train, y_train)
                    y_pred = reg.predict(X_test)

                    mse = mean_squared_error(y_test, y_pred)
                    rmse = np.sqrt(mse)
                    r2 = r2_score(y_test, y_pred)

                    st.write(f"âœ… RMSEï¼š**{rmse:.4f}**")
                    st.write(f"âœ… RÂ²ï¼š**{r2:.4f}**")

                    st.write("ğŸ“‰ y_true vs y_predï¼ˆæ•£ä½ˆåœ–ï¼‰")
                    fig, ax = plt.subplots()
                    ax.scatter(y_test, y_pred, alpha=0.6)
                    ax.set_xlabel("True")
                    ax.set_ylabel("Predicted")
                    ax.set_title("True vs Predicted")
                    st.pyplot(fig)

                    ml_report_lines.append("### å›æ­¸æ¨¡å‹çµæœï¼ˆRandomForestRegressorï¼‰")
                    ml_report_lines.append(f"- RMSEï¼š{rmse:.4f}")
                    ml_report_lines.append(f"- RÂ²ï¼š{r2:.4f}")

                st.session_state["ml_summary"] = "\n".join(ml_report_lines)
                st.success("âœ… AutoML å»ºæ¨¡å®Œæˆï¼Œçµæœå·²å¯«å…¥ Markdown å ±å‘Šæ‘˜è¦ã€‚")

    # =============================
    # Tab 3ï¼šç•°å¸¸åµæ¸¬
    # =============================
    with tab_anom:
        st.header("ğŸš¨ ç•°å¸¸åµæ¸¬ï¼ˆAnomaly Detectionï¼‰")

        if len(numeric_cols) == 0:
            st.warning("æ­¤è³‡æ–™é›†æ²’æœ‰æ•¸å€¼æ¬„ä½ï¼Œç„¡æ³•é€²è¡Œç•°å¸¸åµæ¸¬ã€‚")
        else:
            st.write("é¸æ“‡ç”¨ä¾†åšç•°å¸¸åµæ¸¬çš„æ•¸å€¼æ¬„ä½ï¼š")
            selected_num_cols = st.multiselect(
                "æ•¸å€¼æ¬„ä½ï¼ˆè‡³å°‘é¸ 2 å€‹è¼ƒä½³ï¼‰", numeric_cols, default=numeric_cols
            )

            algo = st.radio(
                "é¸æ“‡ç•°å¸¸åµæ¸¬æ¼”ç®—æ³•",
                ["Isolation Forest", "Local Outlier Factor (LOF)", "å…©è€…éƒ½è·‘"],
                horizontal=True
            )

            contamination = st.slider(
                "é ä¼°ç•°å¸¸æ¯”ä¾‹ contaminationï¼ˆ0~0.2ï¼‰",
                min_value=0.01,
                max_value=0.2,
                value=0.05,
                step=0.01
            )

            if st.button("ğŸš¨ åŸ·è¡Œç•°å¸¸åµæ¸¬"):
                use_cols = selected_num_cols if len(selected_num_cols) > 0 else numeric_cols
                X = df[use_cols].dropna()
                idx = X.index

                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)

                anom_lines = []
                result_df = pd.DataFrame(index=idx)

                # Isolation Forest
                if algo in ["Isolation Forest", "å…©è€…éƒ½è·‘"]:
                    iso = IsolationForest(
                        contamination=contamination,
                        random_state=42
                    )
                    iso_labels = iso.fit_predict(X_scaled)
                    result_df["IF_label"] = iso_labels
                    n_anom_if = (iso_labels == -1).sum()
                    anom_lines.append(f"- Isolation Forest ç•°å¸¸é»æ•¸é‡ï¼š{n_anom_if}")

                # LOF
                if algo in ["Local Outlier Factor (LOF)", "å…©è€…éƒ½è·‘"]:
                    lof = LocalOutlierFactor(
                        contamination=contamination,
                        novelty=False
                    )
                    lof_labels = lof.fit_predict(X_scaled)
                    result_df["LOF_label"] = lof_labels
                    n_anom_lof = (lof_labels == -1).sum()
                    anom_lines.append(f"- LOF ç•°å¸¸é»æ•¸é‡ï¼š{n_anom_lof}")

                out_df = df.join(result_df, how="left")

                st.subheader("ğŸ“‹ ç•°å¸¸åµæ¸¬çµæœï¼ˆå«æ¨™è¨˜æ¬„ä½ï¼‰")
                st.dataframe(out_df.head(20))

                if "IF_label" in result_df.columns and "LOF_label" in result_df.columns:
                    both_anom = result_df[
                        (result_df["IF_label"] == -1) & (result_df["LOF_label"] == -1)
                    ]
                    anom_lines.append(f"- åŒæ™‚è¢« IF èˆ‡ LOF åˆ¤ç‚ºç•°å¸¸çš„è³‡æ–™ç­†æ•¸ï¼š{both_anom.shape[0]}")

                # 2D è¦–è¦ºåŒ–
                if len(use_cols) >= 2:
                    col1, col2 = use_cols[0], use_cols[1]
                    st.subheader(f"ğŸ“‰ 2D ç•°å¸¸é»è¦–è¦ºåŒ–ï¼š{col1} vs {col2}")

                    fig, ax = plt.subplots()
                    ax.scatter(X[col1], X[col2], alpha=0.4, label="Normal")

                    if "IF_label" in result_df.columns:
                        anom_if = X[result_df["IF_label"] == -1]
                        ax.scatter(
                            anom_if[col1], anom_if[col2],
                            marker="x", s=60, label="IF Anomaly"
                        )
                    if "LOF_label" in result_df.columns:
                        anom_lof = X[result_df["LOF_label"] == -1]
                        ax.scatter(
                            anom_lof[col1], anom_lof[col2],
                            facecolors="none", edgecolors="r",
                            s=60, label="LOF Anomaly"
                        )
                    ax.set_xlabel(col1)
                    ax.set_ylabel(col2)
                    ax.legend()
                    st.pyplot(fig)

                st.session_state["anom_summary"] = "### ç•°å¸¸åµæ¸¬çµæœæ‘˜è¦\n" + "\n".join(anom_lines)
                st.success("âœ… ç•°å¸¸åµæ¸¬å®Œæˆï¼Œçµæœå·²å¯«å…¥ Markdown å ±å‘Šæ‘˜è¦ã€‚")

    # =============================
    # Tab 4ï¼šæ™‚é–“åºåˆ—åˆ†æï¼ˆACF / PACF / ARIMAï¼‰
    # =============================
    with tab_ts:
        st.header("â±ï¸ æ™‚é–“åºåˆ—åˆ†æï¼ˆACF / PACF / ARIMAï¼‰")

        if len(numeric_cols) == 0:
            st.warning("æ­¤è³‡æ–™é›†æ²’æœ‰æ•¸å€¼æ¬„ä½ï¼Œç„¡æ³•é€²è¡Œæ™‚é–“åºåˆ—åˆ†æã€‚")
        else:
            # é¸æ“‡æ™‚é–“æ¬„ä½
            if len(candidate_time_cols) == 0:
                st.info("æœªè‡ªå‹•åµæ¸¬åˆ°æ™‚é–“æ¬„ä½ï¼Œè«‹æ‰‹å‹•å¾æ‰€æœ‰æ¬„ä½ä¸­é¸æ“‡ã€‚")
                date_col = st.selectbox("é¸æ“‡æ™‚é–“æ¬„ä½", df.columns, key="ts_date_col_all")
            else:
                date_col = st.selectbox(
                    "é¸æ“‡æ™‚é–“æ¬„ä½",
                    candidate_time_cols,
                    key="ts_date_col"
                )

            y_col = st.selectbox("é¸æ“‡ç›®æ¨™æ•¸å€¼æ¬„ä½ï¼ˆæ™‚é–“åºåˆ— yï¼‰", numeric_cols)

            forecast_steps = st.number_input(
                "é æ¸¬æœªä¾†å¹¾æœŸï¼ˆæ­¥æ•¸ï¼‰", min_value=1, max_value=365, value=30, step=1
            )

            arima_mode = st.radio(
                "é¸æ“‡ ARIMA æ¨¡å¼",
                ["Auto ARIMAï¼ˆpmdarimaï¼‰", "æ‰‹å‹• ARIMAï¼ˆstatsmodelsï¼‰"],
                horizontal=True
            )

            p = d = q = 0
            if arima_mode == "æ‰‹å‹• ARIMAï¼ˆstatsmodelsï¼‰":
                cols = st.columns(3)
                p = cols[0].number_input("pï¼ˆAR éšæ•¸ï¼‰", min_value=0, max_value=10, value=1, step=1)
                d = cols[1].number_input("dï¼ˆå·®åˆ†éšæ•¸ï¼‰", min_value=0, max_value=5, value=1, step=1)
                q = cols[2].number_input("qï¼ˆMA éšæ•¸ï¼‰", min_value=0, max_value=10, value=1, step=1)

            if st.button("â±ï¸ åŸ·è¡Œæ™‚é–“åºåˆ—åˆ†æ"):
                ts_df = df[[date_col, y_col]].dropna().copy()

                # è½‰æˆ datetime
                try:
                    ts_df[date_col] = pd.to_datetime(ts_df[date_col])
                except Exception:
                    st.error("æ™‚é–“æ¬„ä½ç„¡æ³•è½‰æ›ç‚º datetimeï¼Œè«‹ç¢ºèªè³‡æ–™æ ¼å¼ã€‚")
                else:
                    ts_df = ts_df.sort_values(by=date_col)
                    ts_df = ts_df.set_index(date_col)
                    y = ts_df[y_col]

                    st.subheader("ğŸ“‰ åŸå§‹æ™‚é–“åºåˆ—åœ–")
                    fig, ax = plt.subplots()
                    ax.plot(y.index, y.values, label=y_col)
                    ax.set_xlabel("Time")
                    ax.set_ylabel(y_col)
                    ax.legend()
                    st.pyplot(fig)

                    # ç§»å‹•å¹³å‡
                    st.subheader("ğŸ“ˆ ç§»å‹•å¹³å‡ç·šï¼ˆMA7 / MA30ï¼‰")
                    ma_df = pd.DataFrame({
                        "y": y,
                        "MA7": y.rolling(window=7).mean(),
                        "MA30": y.rolling(window=30).mean()
                    })
                    fig, ax = plt.subplots()
                    ax.plot(ma_df.index, ma_df["y"], label="åŸå§‹")
                    ax.plot(ma_df.index, ma_df["MA7"], label="MA7")
                    ax.plot(ma_df.index, ma_df["MA30"], label="MA30")
                    ax.legend()
                    st.pyplot(fig)

                    # ACF / PACF
                    if ts_pkgs["statsmodels_acf"] is None or ts_pkgs["statsmodels_pacf"] is None:
                        st.warning("statsmodels ç„¡æ³•ä½¿ç”¨ï¼Œç„¡æ³•ç¹ªè£½ ACF / PACFã€‚è«‹æª¢æŸ¥ç’°å¢ƒå®‰è£ã€‚")
                    else:
                        plot_acf = ts_pkgs["statsmodels_acf"]
                        plot_pacf = ts_pkgs["statsmodels_pacf"]

                        st.subheader("ğŸ“Š ACFï¼ˆè‡ªç›¸é—œå‡½æ•¸ï¼‰")
                        fig_acf = plt.figure()
                        plot_acf(y.dropna(), ax=plt.gca(), lags=40)
                        st.pyplot(fig_acf)

                        st.subheader("ğŸ“Š PACFï¼ˆåè‡ªç›¸é—œå‡½æ•¸ï¼‰")
                        fig_pacf = plt.figure()
                        plot_pacf(y.dropna(), ax=plt.gca(), lags=40, method="ywm")
                        st.pyplot(fig_pacf)

                    ts_lines = []
                    ts_lines.append(f"### æ™‚é–“åºåˆ—åˆ†ææ‘˜è¦ï¼ˆç›®æ¨™æ¬„ä½ï¼š{y_col}ï¼‰")
                    ts_lines.append(f"- è³‡æ–™ç­†æ•¸ï¼š{len(y)}")
                    ts_lines.append(f"- æ™‚é–“ç¯„åœï¼š{y.index.min()} ~ {y.index.max()}")

                    # ARIMA æ¨¡å‹
                    forecast_index = None
                    forecast_values = None

                    if arima_mode == "Auto ARIMAï¼ˆpmdarimaï¼‰":
                        if ts_pkgs["pmdarima"] is None:
                            st.error("pmdarima ç„¡æ³•ä½¿ç”¨ï¼Œè«‹æª¢æŸ¥ç’°å¢ƒå®‰è£ã€‚")
                        else:
                            pm = ts_pkgs["pmdarima"]
                            st.subheader("ğŸ¤– Auto ARIMAï¼ˆpmdarimaï¼‰")
                            try:
                                auto_model = pm.auto_arima(
                                    y,
                                    seasonal=False,
                                    stepwise=True,
                                    error_action="ignore",
                                    suppress_warnings=True
                                )
                                st.write(f"æœ€ä½³ ARIMA æ¨¡å‹ï¼š{auto_model.order}")
                                ts_lines.append(f"- Auto ARIMA æœ€ä½³æ¨¡å‹ï¼šARIMA{auto_model.order}")

                                forecast_values = auto_model.predict(n_periods=forecast_steps)
                                last_index = y.index[-1]
                                # ä»¥å›ºå®šé »ç‡æ¨ä¼° indexï¼ˆè‹¥ç„¡ freq å‰‡ä»¥å¤©ç‚ºå–®ä½ï¼‰
                                freq = y.index.freq or pd.infer_freq(y.index)
                                if freq is None:
                                    freq = "D"
                                forecast_index = pd.date_range(
                                    start=last_index, periods=forecast_steps+1, freq=freq
                                )[1:]

                                forecast_series = pd.Series(forecast_values, index=forecast_index)

                                st.subheader("ğŸ”® é æ¸¬çµæœ")
                                fig, ax = plt.subplots()
                                ax.plot(y.index, y.values, label="æ­·å²")
                                ax.plot(forecast_series.index, forecast_series.values, label="é æ¸¬")
                                ax.legend()
                                st.pyplot(fig)

                                ts_lines.append(f"- é æ¸¬æ­¥æ•¸ï¼š{forecast_steps}")
                                ts_lines.append(f"- é æ¸¬å‡å€¼ï¼š{forecast_series.mean():.4f}")
                                ts_lines.append(f"- é æ¸¬æœ€å°å€¼ï¼š{forecast_series.min():.4f}")
                                ts_lines.append(f"- é æ¸¬æœ€å¤§å€¼ï¼š{forecast_series.max():.4f}")

                            except Exception as e:
                                st.error(f"Auto ARIMA æ“¬åˆå¤±æ•—ï¼š{e}")

                    else:  # æ‰‹å‹• ARIMA
                        if ts_pkgs["ARIMA"] is None:
                            st.error("statsmodels.ARIMA ç„¡æ³•ä½¿ç”¨ï¼Œè«‹æª¢æŸ¥ç’°å¢ƒå®‰è£ã€‚")
                        else:
                            ARIMA = ts_pkgs["ARIMA"]
                            st.subheader("ğŸ§® æ‰‹å‹• ARIMAï¼ˆstatsmodelsï¼‰")
                            try:
                                order = (int(p), int(d), int(q))
                                st.write(f"ä½¿ç”¨ ARIMA{order}")
                                model = ARIMA(y, order=order)
                                model_fit = model.fit()
                                st.text(model_fit.summary().as_text()[:800])

                                forecast_res = model_fit.get_forecast(steps=forecast_steps)
                                forecast_values = forecast_res.predicted_mean
                                conf_int = forecast_res.conf_int()

                                last_index = y.index[-1]
                                freq = y.index.freq or pd.infer_freq(y.index)
                                if freq is None:
                                    freq = "D"
                                forecast_index = pd.date_range(
                                    start=last_index, periods=forecast_steps+1, freq=freq
                                )[1:]
                                forecast_values.index = forecast_index
                                conf_int.index = forecast_index

                                st.subheader("ğŸ”® é æ¸¬çµæœ + ä¿¡è³´å€é–“")
                                fig, ax = plt.subplots()
                                ax.plot(y.index, y.values, label="æ­·å²")
                                ax.plot(forecast_values.index, forecast_values.values, label="é æ¸¬")
                                ax.fill_between(
                                    conf_int.index,
                                    conf_int.iloc[:, 0],
                                    conf_int.iloc[:, 1],
                                    alpha=0.3,
                                    label="ä¿¡è³´å€é–“"
                                )
                                ax.legend()
                                st.pyplot(fig)

                                ts_lines.append(f"- æ‰‹å‹• ARIMA æ¨¡å‹ï¼šARIMA{order}")
                                ts_lines.append(f"- é æ¸¬æ­¥æ•¸ï¼š{forecast_steps}")
                                ts_lines.append(f"- é æ¸¬å‡å€¼ï¼š{forecast_values.mean():.4f}")
                                ts_lines.append(f"- é æ¸¬æœ€å°å€¼ï¼š{forecast_values.min():.4f}")
                                ts_lines.append(f"- é æ¸¬æœ€å¤§å€¼ï¼š{forecast_values.max():.4f}")

                            except Exception as e:
                                st.error(f"ARIMA æ“¬åˆå¤±æ•—ï¼š{e}")

                    st.session_state["ts_summary"] = "\n".join(ts_lines)
                    st.success("âœ… æ™‚é–“åºåˆ—åˆ†æå®Œæˆï¼Œçµæœå·²å¯«å…¥ Markdown å ±å‘Šæ‘˜è¦ã€‚")

    # =============================
    # Tab 5ï¼šMarkdown å ±å‘Šï¼ˆæ•™å­¸ç‰ˆï¼‰
    # =============================
    with tab_report:
        st.header("ğŸ“„ è‡ªå‹•ç”¢ç”Ÿ Markdown æ•™å­¸å ±å‘Š")

        missing_df = df.isnull().sum().to_frame("ç¼ºå¤±æ•¸é‡")
        missing_df["ç¼ºå¤±æ¯”ä¾‹ (%)"] = (missing_df["ç¼ºå¤±æ•¸é‡"] / len(df)) * 100
        top_missing = missing_df.sort_values("ç¼ºå¤±æ•¸é‡", ascending=False).head(10)

        dtypes_str = df.dtypes.astype(str).to_frame("dtype")
        numeric_stats = df[numeric_cols].describe().T if len(numeric_cols) > 0 else pd.DataFrame()

        report_lines = []

        report_lines.append("# ğŸ“Š è‡ªå‹•åŒ– EDA + AutoML + ç•°å¸¸åµæ¸¬ + æ™‚é–“åºåˆ—åˆ†æ å ±å‘Š\n")
        report_lines.append("## 1. åŸºæœ¬è³‡æ–™è³‡è¨Š\n")
        report_lines.append(f"- è³‡æ–™ç­†æ•¸ï¼š{df.shape[0]}")
        report_lines.append(f"- æ¬„ä½æ•¸ï¼š{df.shape[1]}\n")

        report_lines.append("## 2. æ¬„ä½å‹æ…‹æ¦‚æ³\n")
        report_lines.append(dtypes_str.to_markdown())

        report_lines.append("\n## 3. ç¼ºå¤±å€¼åˆ†æï¼ˆå‰ 10 åï¼‰\n")
        report_lines.append(top_missing.to_markdown())

        if len(numeric_cols) > 0:
            report_lines.append("\n## 4. æ•¸å€¼æ¬„ä½æè¿°çµ±è¨ˆ\n")
            report_lines.append(numeric_stats.to_markdown())

        report_lines.append("\n## 5. AutoML æ¨¡å‹æ‘˜è¦\n")
        report_lines.append(st.session_state.get("ml_summary", "å°šæœªåŸ·è¡Œ ML å»ºæ¨¡ã€‚"))

        report_lines.append("\n## 6. ç•°å¸¸åµæ¸¬æ‘˜è¦\n")
        report_lines.append(st.session_state.get("anom_summary", "å°šæœªåŸ·è¡Œç•°å¸¸åµæ¸¬ã€‚"))

        report_lines.append("\n## 7. æ™‚é–“åºåˆ—åˆ†ææ‘˜è¦\n")
        report_lines.append(st.session_state.get("ts_summary", "å°šæœªåŸ·è¡Œæ™‚é–“åºåˆ—åˆ†æã€‚"))

        report_lines.append("\n---\n")
        report_lines.append("æœ¬å ±å‘Šç”± Streamlit è‡ªå‹•ç”¢ç”Ÿï¼Œå¯ä½œç‚ºæ•™å­¸ç¯„ä¾‹æˆ–å°ˆæ¡ˆåˆæ­¥åˆ†æå ±å‘Šä½¿ç”¨ã€‚")

        report_md = "\n".join(report_lines)

        st.subheader("ğŸ“Œ å ±å‘Šé è¦½ï¼ˆMarkdownï¼‰")
        st.markdown(report_md)

        st.download_button(
            label="ğŸ’¾ ä¸‹è¼‰ Markdown å ±å‘Š (.md)",
            data=report_md,
            file_name="eda_automl_anomaly_timeseries_report.md",
            mime="text/markdown"
        )

else:
    st.info("è«‹å…ˆæ–¼å·¦å´ä¸Šå‚³ CSV æª”æ¡ˆï¼Œä»¥é–‹å§‹è‡ªå‹•åŒ–åˆ†ææµç¨‹ã€‚")

```
