# ğŸ“˜ TF-IDF æ•™å­¸æ–‡ä»¶

## ç›®éŒ„
1. [ä»€éº¼æ˜¯ TF-IDF](#ä»€éº¼æ˜¯-tf-idf)
2. [æ•¸å­¸å®šç¾©èˆ‡å…¬å¼](#æ•¸å­¸å®šç¾©èˆ‡å…¬å¼)
3. [ç›´è¦ºç†è§£](#ç›´è¦ºç†è§£)
4. [Python å¯¦ä½œï¼ˆscikit-learnï¼‰](#python-å¯¦ä½œscikit-learn)
5. [æ‰‹å‹•è¨ˆç®—ç¯„ä¾‹ï¼ˆç´” Pythonï¼‰](#æ‰‹å‹•è¨ˆç®—ç¯„ä¾‹ç´”-python)
6. [å¸¸è¦‹æ‡‰ç”¨](#å¸¸è¦‹æ‡‰ç”¨)
7. [å»¶ä¼¸æŠ€è¡“](#å»¶ä¼¸æŠ€è¡“)
8. [è¦–è¦ºåŒ–ç¯„ä¾‹](#è¦–è¦ºåŒ–ç¯„ä¾‹)
9. [åƒè€ƒè³‡æ–™](#åƒè€ƒè³‡æ–™)

---

## ğŸ”¹ ä»€éº¼æ˜¯ TF-IDF
**TF-IDFï¼ˆTerm Frequency â€“ Inverse Document Frequencyï¼‰** æ˜¯ä¸€ç¨®è¡¡é‡è©èªåœ¨æ–‡ä»¶é›†åˆä¸­é‡è¦æ€§çš„æ–¹æ³•ï¼Œå¸¸ç”¨æ–¼ï¼š
- æ–‡ä»¶æª¢ç´¢ï¼ˆå¦‚æœå°‹å¼•æ“ï¼‰
- æ–‡æœ¬åˆ†é¡ï¼ˆå¦‚åƒåœ¾éƒµä»¶åˆ†é¡ï¼‰
- ç‰¹å¾µæå–ï¼ˆå¦‚æ©Ÿå™¨å­¸ç¿’æ–‡æœ¬è¡¨ç¤ºï¼‰

å®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> ä¸€å€‹è©è‹¥åœ¨æŸç¯‡æ–‡ä»¶ä¸­å‡ºç¾é »ç¹ï¼Œä½†åœ¨å…¶ä»–æ–‡ä»¶ä¸­å¾ˆå°‘å‡ºç¾ï¼Œå‰‡è©²è©å°é€™ç¯‡æ–‡ä»¶å…·æœ‰é«˜æ¬Šé‡ã€‚

---

## ğŸ”¹ æ•¸å­¸å®šç¾©èˆ‡å…¬å¼

### (1) Term Frequency (TF)
è¡¡é‡è©èªåœ¨æ–‡ä»¶ä¸­å‡ºç¾çš„é »ç‡ã€‚

\[
TF(t, d) = \frac{\text{è© t åœ¨æ–‡ä»¶ d ä¸­å‡ºç¾æ¬¡æ•¸}}{\text{æ–‡ä»¶ d ä¸­æ‰€æœ‰è©çš„ç¸½æ•¸}}
\]

### (2) Inverse Document Frequency (IDF)
è¡¡é‡è©èªåœ¨æ‰€æœ‰æ–‡ä»¶ä¸­å‡ºç¾çš„æ™®éæ€§ï¼ˆè¶Šæ™®é â†’ è¶Šä¸é‡è¦ï¼‰ã€‚

\[
IDF(t) = \log \frac{N}{1 + df(t)}
\]

å…¶ä¸­ï¼š
- \( N \)ï¼šæ–‡ä»¶ç¸½æ•¸  
- \( df(t) \)ï¼šåŒ…å«è© \( t \) çš„æ–‡ä»¶æ•¸é‡  
- åŠ ä¸Š 1 é˜²æ­¢åˆ†æ¯ç‚ºé›¶

### (3) TF-IDF åŠ æ¬Š
\[
TF\text{-}IDF(t, d) = TF(t, d) \times IDF(t)
\]

---

## ğŸ”¹ ç›´è¦ºç†è§£

| è©èª | åœ¨æ–‡ä»¶Aå‡ºç¾æ¬¡æ•¸ | åœ¨æ‰€æœ‰æ–‡ä»¶ä¸­å‡ºç¾æ¬¡æ•¸ | è§£é‡‹ |
|------|----------------|--------------------|------|
| data | 10             | 100                | å¸¸è¦‹å­—ï¼Œæ¬Šé‡ä½ |
| mining | 3             | 10                 | åœ¨å°‘æ•¸æ–‡ä»¶å‡ºç¾ï¼Œæ¬Šé‡é«˜ |
| the | 15              | 500                | åœç”¨è©ï¼Œæ¬Šé‡å¹¾ä¹ç‚º0 |

TF ä»£è¡¨ã€Œå±€éƒ¨é‡è¦æ€§ã€ï¼ŒIDF ä»£è¡¨ã€Œå…¨åŸŸç¨€æœ‰æ€§ã€â€”â€”å…©è€…çµåˆå¾Œå¯å¼·åŒ–é—œéµå­—ã€‚

---

## ğŸ”¹ Python å¯¦ä½œï¼ˆscikit-learnï¼‰

```python
from sklearn.feature_extraction.text import TfidfVectorizer

# ç¯„ä¾‹æ–‡ä»¶é›†
docs = [
    "I love machine learning and data mining",
    "Data mining is a key technique in machine learning",
    "Deep learning drives AI innovation"
]

# å»ºç«‹ TF-IDF å‘é‡åŒ–å™¨
vectorizer = TfidfVectorizer(stop_words='english')

# è¨ˆç®— TF-IDF çŸ©é™£
tfidf_matrix = vectorizer.fit_transform(docs)

# å–å¾—è©å½™åˆ—è¡¨
words = vectorizer.get_feature_names_out()

# é¡¯ç¤ºçµæœ
import pandas as pd
df = pd.DataFrame(tfidf_matrix.toarray(), columns=words)
print(df.round(3))
```

ğŸ“Š **è¼¸å‡ºç¤ºä¾‹ï¼š**
|     | ai | data | deep | drives | key | learning | love | machine | mining | technique |
|-----|----|------|------|--------|-----|-----------|------|----------|---------|------------|
|æ–‡æª”1|0.0|0.447|0.0|0.0|0.0|0.447|0.547|0.447|0.447|0.0|
|æ–‡æª”2|0.0|0.333|0.0|0.0|0.516|0.333|0.0|0.333|0.516|0.516|
|æ–‡æª”3|0.577|0.0|0.577|0.577|0.0|0.0|0.0|0.0|0.0|0.0|

---

## ğŸ”¹ æ‰‹å‹•è¨ˆç®—ç¯„ä¾‹ï¼ˆç´” Pythonï¼‰

```python
import math
from collections import Counter

docs = [
    "data science is fun",
    "machine learning uses data science",
    "deep learning and data"
]

# è¨ˆç®— TF
tf_list = []
for doc in docs:
    words = doc.split()
    count = Counter(words)
    total = len(words)
    tf = {w: count[w] / total for w in count}
    tf_list.append(tf)

# è¨ˆç®— DF
df = Counter()
for tf in tf_list:
    for term in tf:
        df[term] += 1

# è¨ˆç®— IDF
N = len(docs)
idf = {term: math.log(N / (1 + df[term])) for term in df}

# è¨ˆç®— TF-IDF
tfidf = []
for tf in tf_list:
    tfidf_doc = {term: tf[term] * idf[term] for term in tf}
    tfidf.append(tfidf_doc)

print(tfidf)
```

---

## ğŸ”¹ å¸¸è¦‹æ‡‰ç”¨
| æ‡‰ç”¨é ˜åŸŸ | èªªæ˜ |
|-----------|------|
| ğŸ” æœå°‹å¼•æ“æ’åº | æ¯”è¼ƒæŸ¥è©¢è©èˆ‡æ–‡ä»¶çš„ TF-IDF å‘é‡ç›¸ä¼¼åº¦ï¼ˆä¾‹å¦‚ cosine similarityï¼‰ |
| ğŸ“§ åƒåœ¾éƒµä»¶åˆ†é¡ | è½‰æ›éƒµä»¶å…§å®¹ç‚º TF-IDF ç‰¹å¾µå¾Œé€å…¥æ©Ÿå™¨å­¸ç¿’æ¨¡å‹ |
| ğŸ§  ä¸»é¡Œå»ºæ¨¡ | èˆ‡ LDAã€NMF çµåˆç”¨æ–¼é—œéµè©èƒå– |
| ğŸ—‚ï¸ æ–‡ä»¶èšé¡ | ä½¿ç”¨ TF-IDF å‘é‡é€²è¡Œ K-Means èšé¡ |

---

## ğŸ”¹ å»¶ä¼¸æŠ€è¡“
| æŠ€è¡“åç¨± | èªªæ˜ |
|-----------|------|
| **n-gram TF-IDF** | è€ƒæ…®è©çµ„ï¼ˆå¦‚ã€Œmachine learningã€ï¼‰çš„æ¬Šé‡ |
| **TF-IDF + SVD (LSA)** | é€²è¡Œé™ç¶­ï¼Œæå–èªç¾©ä¸»æˆåˆ† |
| **TF-IDF + Word2Vec/BERT** | æ··åˆåµŒå…¥æ–¹æ³•ï¼Œæå‡èªç¾©ç†è§£èƒ½åŠ› |

---

## ğŸ”¹ è¦–è¦ºåŒ–ç¯„ä¾‹

```python
import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(df, cmap="YlGnBu")
plt.title("TF-IDF Heatmap")
plt.xlabel("Terms")
plt.ylabel("Documents")
plt.show()
```

é€™æ®µç¨‹å¼ç¢¼å¯å°‡ TF-IDF æ¬Šé‡ä»¥ç†±åœ–æ–¹å¼è¦–è¦ºåŒ–ï¼Œå¹«åŠ©äº†è§£æ¯å€‹è©åœ¨ä¸åŒæ–‡ä»¶çš„é‡è¦ç¨‹åº¦ã€‚

---

## ğŸ”¹ åƒè€ƒè³‡æ–™
- [scikit-learn TfidfVectorizer å®˜æ–¹æ–‡ä»¶](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)
- [Stanford NLP èª²ç¨‹ç­†è¨˜](https://web.stanford.edu/class/cs124/)
- Manning, Raghavan, SchÃ¼tze. *Introduction to Information Retrieval* (Cambridge University Press)

