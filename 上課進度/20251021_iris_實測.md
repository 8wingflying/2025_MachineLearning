# ğŸŒ¸ ä½¿ç”¨ 10 ç¨®ç›£ç£å¼èˆ‡ 4 ç¨®éç›£ç£å¼æ©Ÿå™¨å­¸ç¿’æ¼”ç®—æ³•åˆ†æ Iris è³‡æ–™é›†

---

## ğŸ“˜ ä¸€ã€è³‡æ–™é›†ä»‹ç´¹

- **è³‡æ–™ä¾†æº**ï¼š`sklearn.datasets.load_iris()`
- **ç‰¹å¾µ (features)**ï¼š
  - èŠ±è¼é•·åº¦ï¼ˆsepal lengthï¼‰
  - èŠ±è¼å¯¬åº¦ï¼ˆsepal widthï¼‰
  - èŠ±ç“£é•·åº¦ï¼ˆpetal lengthï¼‰
  - èŠ±ç“£å¯¬åº¦ï¼ˆpetal widthï¼‰
- **æ¨™ç±¤ (labels)**ï¼š
  - 0 = Iris setosa  
  - 1 = Iris versicolor  
  - 2 = Iris virginica

---

## ğŸ“¦ äºŒã€è¼‰å…¥èˆ‡åˆ†å‰²è³‡æ–™

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
```

## ç›£ç£å¼
```
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier

models = {
    "LogisticRegression": LogisticRegression(max_iter=200),
    "KNN": KNeighborsClassifier(),
    "SVM": SVC(),
    "DecisionTree": DecisionTreeClassifier(),
    "RandomForest": RandomForestClassifier(),
    "GradientBoosting": GradientBoostingClassifier(),
    "AdaBoost": AdaBoostClassifier(),
    "NaiveBayes": GaussianNB(),
    "ExtraTrees": ExtraTreesClassifier(),
    "MLPClassifier": MLPClassifier(max_iter=500)
}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print(f"{name:20s} æº–ç¢ºç‡: {accuracy_score(y_test, y_pred):.4f}")

```

## éç›£ç£å¼
```
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# PCA é™ç¶­è‡³ 2 ç¶­æ–¹ä¾¿è¦–è¦ºåŒ–
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

algorithms = {
    "KMeans": KMeans(n_clusters=3, random_state=42),
    "DBSCAN": DBSCAN(eps=0.5, min_samples=5),
    "Agglomerative": AgglomerativeClustering(n_clusters=3)
}

fig, axes = plt.subplots(1, 3, figsize=(15, 4))
for ax, (name, algo) in zip(axes, algorithms.items()):
    labels = algo.fit_predict(X_pca)
    ax.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='rainbow')
    ax.set_title(name)
plt.show()
```
